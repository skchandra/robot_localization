- What was the goal of your project?
    The overarching goal of this project was to determine how to implement a particle filter that uses odometry with the laser scan in order to create an accurate estimation of robotâ€™s location on a provided map. Once we accomplished that, we focused on fine-tuning our parameters in order to make the estimation even more precise. 

- How did you solve the problem? (Note: this doesn't have to be super-detailed, you should try to explain what you did at a high-level so that others in the class could reasonably understand what you did).
    We first create a cloud of particles, which uses a Gaussian distribution to create feasible positions of the robot around an initial guess. Odometry is then used to receive and calculate the change in pose orientation and theta, which is applied to update the particle positions. Next, the data from the lidar is used -- for each angle that the robot senses an object (the sensor reading is not 0.0), the particle cloud is iterated through to find the closest object to each particle and compare that to the laser scan reading, giving us the particle weight. By doing this for every particle at each angle, we are then able to get an average weight for each particle, which is then normalized and used to updated the robot pose. The pose is updated by determining the mean position of all the particles in the cloud, meaning the x-pos, y-pos, and theta, all multiplied by their respective weights (the higher the weight, the more it affects the position of the robot). 

- Describe a design decision you had to make when working on your project and what you ultimately did (and why)? These design decisions could be particular choices for how you implemented some part of an algorithm or perhaps a decision regarding which of two external packages to use in your project.
    When we incorporate lidar data in order to update particle weights, we decided to use a nested for loop to iterate through the particle cloud for each angle of the scan. While this could potentially take a large amount of time, we felt it was a safe decision to make because our particle number is relatively low (300). At first, we also tried to account for this by using a dictionary in the loop rather than a list for quicker lookup times, but ended up not looking up keys (though we kept the dictionary). 

- What if any challenges did you face along the way?
    We faced difficulty mainly in two stages: one, in visualizing the mathematical transformations from one coordinate system to another, especially while debugging, and the other in figuring out when to fine-tune parameters rather than change our code. For the most part, we were able to solve these challenges through extensive use of rviz and printing out individual variables to check our math. 

- What would you do to improve your project if you had more time?
    If we had more time, it would be interesting to implement a feature that could recognize and reset the particle cloud once it reached a dead end, because currently once the cloud loses track of a feasible robot position, it ultimately ends up failing. Additionally, there were certain cases where parts of the map had the same structure, which caused the filter to become unreliable, so addressing that would definitely be on the list. 

- Did you learn any interesting lessons for future robotic programming projects? These could relate to working on robotics projects in teams, working on more open-ended (and longer term) problems, or any other relevant topic.
    We learned a lot about how to effectively design algorithms to perform tasks, especially when it comes to simplifying them and cutting down on runtime -- if our code takes too long, the filter can become out of sync with the robot sensor updates. Additionally, we learned some good practices to use while debugging; because so many parts of the code were dependent on each other, it was sometimes a challenge to figure out exactly how to go about testing each function and isolating the problem. 